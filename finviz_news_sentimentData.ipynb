{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be3912fe",
   "metadata": {},
   "source": [
    "# This notebook performs sentiment analysis on financial news headlines from Finviz for specific stock symbols. Here is a detailed summary of each step:\n",
    "\n",
    "\n",
    "The first cell installs the necessary Python libraries: requests, beautifulsoup4, pandas, and vaderSentiment.\n",
    "Importing Libraries:\n",
    "\n",
    "The second cell imports the libraries: requests for making HTTP requests, BeautifulSoup from bs4 for web scraping, pandas for data manipulation, and SentimentIntensityAnalyzer from vaderSentiment for sentiment analysis.\n",
    "Scraping Finviz News Headlines:\n",
    "\n",
    "The third cell defines a function to scrape news headlines for a given stock symbol from the Finviz website.\n",
    "Sentiment Analysis Function:\n",
    "\n",
    "The fourth cell contains a function that performs sentiment analysis on the scraped headlines using VADER, a sentiment analysis tool that measures the polarity of text (positive, negative, neutral).\n",
    "Main Execution Block:\n",
    "\n",
    "The fifth cell is the main execution block. It lists stock symbols (e.g., ONCO, CNEY, TNXP, APLD, KTTA) and scrapes headlines for each symbol, analyzing their sentiment and storing the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "055ddfb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\priyanka\\anaconda3\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\priyanka\\anaconda3\\lib\\site-packages (4.12.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\priyanka\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Collecting vaderSentiment\n",
      "  Obtaining dependency information for vaderSentiment from https://files.pythonhosted.org/packages/76/fc/310e16254683c1ed35eeb97386986d6c00bc29df17ce280aed64d55537e9/vaderSentiment-3.3.2-py2.py3-none-any.whl.metadata\n",
      "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl.metadata (572 bytes)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\priyanka\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\priyanka\\anaconda3\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\priyanka\\anaconda3\\lib\\site-packages (from requests) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\priyanka\\anaconda3\\lib\\site-packages (from requests) (2023.7.22)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\priyanka\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.4)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\priyanka\\anaconda3\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\priyanka\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\priyanka\\anaconda3\\lib\\site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\priyanka\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\priyanka\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
      "   ---------------------------------------- 0.0/126.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 126.0/126.0 kB 3.7 MB/s eta 0:00:00\n",
      "Installing collected packages: vaderSentiment\n",
      "Successfully installed vaderSentiment-3.3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install requests beautifulsoup4 pandas vaderSentiment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87afccb5",
   "metadata": {},
   "source": [
    "## Installs the libraries needed for web scraping, data manipulation, and sentiment analysis.\n",
    "requests: For sending HTTP requests to fetch web content.\n",
    "beautifulsoup4: For parsing and scraping HTML content.\n",
    "pandas: For handling data structures, such as data frames.\n",
    "vaderSentiment: For performing sentiment analysis on text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d396038",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f279825",
   "metadata": {},
   "source": [
    "## Defines a function to scrape financial news headlines for a specified stock from Finviz.\n",
    "Uses the stock symbol to create the URL for the stock's news page.\n",
    "Sends a GET request to the URL to fetch the page content.\n",
    "Uses BeautifulSoup to parse the HTML and find the news table containing the headlines.\n",
    "Extracts and returns a list of headlines from the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4ff867d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to scrape headlines from Finviz for a specific stock\n",
    "def get_finviz_news(stock_symbol):\n",
    "    url = f\"https://finviz.com/quote.ashx?t={stock_symbol}&p=d\"  # Using the provided URL format\n",
    "    \n",
    "    # Add headers to mimic a real browser request\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # Extract news table\n",
    "    news_table = soup.find('table', class_='fullview-news-outer')\n",
    "    \n",
    "    # Handle the case where the table is not found\n",
    "    if news_table is None:\n",
    "        print(f\"No news found for {stock_symbol}\")\n",
    "        return []\n",
    "    \n",
    "    # List to hold news\n",
    "    news = []\n",
    "    \n",
    "    # Iterate through table rows\n",
    "    for row in news_table.findAll('tr'):\n",
    "        news_time = row.td.text.strip()  # Extract date and time\n",
    "        headline = row.a.text.strip()    # Extract headline\n",
    "        news.append({\"Date\": news_time, \"Headline\": headline})\n",
    "    \n",
    "    return news\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bcfe20",
   "metadata": {},
   "source": [
    "## Defines a function that takes a list of headlines and performs sentiment analysis on each one.\n",
    "Creates an instance of SentimentIntensityAnalyzer.\n",
    "Loops through each headline and calculates the sentiment score, which includes positive, negative, neutral, and compound scores.\n",
    "Prints the headline along with its sentiment scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3944ba2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform sentiment analysis on the headlines\n",
    "def analyze_sentiment(headlines):\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    \n",
    "    # Analyze sentiment for each headline\n",
    "    for headline in headlines:\n",
    "        sentiment_score = analyzer.polarity_scores(headline['Headline'])['compound']\n",
    "        headline['Sentiment'] = sentiment_score\n",
    "    \n",
    "    return headlines\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8194dd",
   "metadata": {},
   "source": [
    "## Demonstrates how to use the functions to get headlines and analyze sentiment.\n",
    "Defines a list of stock symbols to analyze.\n",
    "Scrapes headlines for each stock symbol and stores them in a list.\n",
    "Creates a pandas DataFrame to organize the headlines.\n",
    "Calls the analyze_sentiment function to evaluate the sentiment of each headline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b5ac5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Stock Symbol               Date  \\\n",
      "0           ONCO  Sep-20-24 11:45AM   \n",
      "1           ONCO  Jul-15-24 06:00AM   \n",
      "2           ONCO  Jul-11-24 08:17AM   \n",
      "3           ONCO  May-30-24 07:47AM   \n",
      "4           ONCO  May-21-24 09:52AM   \n",
      "..           ...                ...   \n",
      "421         KTTA            07:30AM   \n",
      "422         KTTA  Nov-11-21 08:00AM   \n",
      "423         KTTA  Nov-09-21 08:00AM   \n",
      "424         KTTA  Oct-27-21 11:40AM   \n",
      "425         KTTA            07:45AM   \n",
      "\n",
      "                                              Headline  Sentiment  \n",
      "0    Onconetix, Inc. Announces 1-for-40 Reverse Sto...     0.0000  \n",
      "1    Onconetix Announces Closing of Warrant Exercis...    -0.4767  \n",
      "2    Onconetix Announces Exercise of Warrants for $...    -0.4767  \n",
      "3    Today's Biggest Pre-Market Stock Movers: 10 To...    -0.3818  \n",
      "4    ONCO Stock Earnings: Onconetix Reported Result...     0.0000  \n",
      "..                                                 ...        ...  \n",
      "421  EXCLUSIVE: Pasithea Clinics Launches In-Home I...     0.3034  \n",
      "422  Pasithea Therapeutics Collaborates with Renown...     0.2732  \n",
      "423  Pasithea Therapeutics Corp. Establishes Scient...     0.0000  \n",
      "424  Biotech Companies Are Embracing the Growing Ps...    -0.4767  \n",
      "425  Pasithea Therapeutics Announces Successful Tre...     0.5859  \n",
      "\n",
      "[426 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    symbols = ['ONCO', 'CNEY', 'TNXP', 'APLD', 'KTTA']  # List of stock symbols\n",
    "    \n",
    "    # List to hold all headlines and their sentiment\n",
    "    all_headlines = []\n",
    "    \n",
    "    for symbol in symbols:\n",
    "        # Scrape news for each symbol\n",
    "        headlines = get_finviz_news(symbol)\n",
    "        # Perform sentiment analysis\n",
    "        if headlines:\n",
    "            headlines_with_sentiment = analyze_sentiment(headlines)\n",
    "            # Add stock symbol to the data\n",
    "            for headline in headlines_with_sentiment:\n",
    "                headline['Stock Symbol'] = symbol\n",
    "            all_headlines.extend(headlines_with_sentiment)\n",
    "    \n",
    "    # Create a DataFrame from the list of headlines with sentiment\n",
    "    headlines_df = pd.DataFrame(all_headlines)\n",
    "    \n",
    "    # Display the DataFrame\n",
    "    print(headlines_df[['Stock Symbol', 'Date', 'Headline', 'Sentiment']])\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53120e4",
   "metadata": {},
   "source": [
    "## Saves the DataFrame containing the stock symbols and headlines to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "417f120f",
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Optionally, save to CSV for further analysis\n",
    "headlines_df.to_csv('finviz_news_sentiment.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b158d474",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
